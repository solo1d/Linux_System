# 虚拟内存

为了更加有效地管理**内存**且少出错，现代系统提供了对**主存**的抽象概念，叫做`虚拟内存(VM）`。

* `虚拟内存`是硬件异常，硬件地址翻译，主存，磁盘文件和内核软件的完美交互。
* 为每个进程提供一个**大的**，**一致的**和 **私有的**地址空间。
* 提供了3个重要能力。
  * 将主存看成磁盘地址空间的**高速缓存**。
    * 只保留了活动区域，并根据需要在磁盘和主存间来回传送数据，高效使用主存。
  * 为每个进程提供**一致**的地址空间
    * 简化内存管理
  * 保护了每个进程的地址空间不被其他进程破坏。
* 程序员为什么要理解它？
  * `虚拟内存`是中心的。
    * 遍布在计算机系统所有层次，硬件异常，汇编器，连接器，加载器，共享对象，文件和进程中扮演重要角色。
  * `虚拟内存`是强大的。
    * 可以创建和销毁内存片\(chunk\)
    * 将内存片映射到磁盘文件的某个部分。
    * 其他进程共享内存。
    * **例子**
      * 能读写内存位置来修改磁盘文件内容。
      * 加载文件到内存不需要显式的拷贝。
  * `虚拟内存`是危险的
    * 引用变量，间接引用指正，调用`malloc`动态分配程序，就会和虚拟内存交互。
    * 如果使用不当，将遇到复杂危险的与内存有关的错误。
    * **例子**
      * 一个带有错误指针的程序可以立即崩溃于**段错误**或者**保护错误**。
      * 运行完成，却不产生正确结果。
* 本章从两个角度分析。
  * `虚拟内存`如何工作。
  * 应用程序如何使用和管理`虚拟内存`。

## 物理和虚拟寻址

* `物理地址(Physical Address,PA)`:计算机系统的主存被组织为M个连续的字节大小的单元组成的数组。每个字节的地址叫`物理地址`.
* CPU访问内存的最自然的方式使用`物理地址`，这种方式称为`物理寻址`。 - 早期的PC，数字信号处理器，嵌入式微控制器以及Cray超级计算机使用`物理寻址`。
* 现代处理器使用的是`虚拟寻址(virtual addressing)`的寻址形式。![](http://i.imgur.com/bZ0LJzw.png)
  * CPU通过生成一个`虚拟地址(Virtual address,VA)`来访问主存。
    * 将`虚拟地址`转换为`物理地址`叫做`地址翻译(address translation)`。
  * `地址翻译`也需要CPU硬件和操作系统之间的紧密结合。
    * CPU芯片上有叫做`内存管理单元(Memory Management Unit,MMU)`的专用硬件。
      * 利用存储在主存中的查询表来动态翻译虚拟地址。
      * 查询表由操作系统管理。

## 地址空间

`地址空间(address space)`是一个非负整数`地址`的有序集合。

* 如果地址空间中整数是连续的，我们说它是`线性地址空间(linear address space)`。
  * 为了简化讨论，我们总是假设使用线性地址空间。
* 在一个带虚拟内存的系统中，CPU从一个有`N=2^n`个地址的`地址空间`中生成虚拟地址，这个地址空间称为`虚拟地址空间(virtual address space)`。
* 一个`地址空间`大小是由**表示最大地址所需要的位数**来描述的。
  * 如`N=2^n`个地址的虚拟地址空间叫做`n`位地址空间。
  * 现在操作系统支持`32位`或`64位`。
* 一个系统还有`物理地址空间`,它与系统中物理内存的`M=2^m`\(假设为2的幂\)个字节相对应。

`地址空间`的概念很重要，因为它区分了**数据对象\(字节\)**和 它们的**属性\(地址\)**。

* 每个`字节(数据对象)`一般有**多个** 独立的`地址(属性)`。每个地址都选自**不同**的地址空间。
  * 比如一般来说。
    * `字节` 有一个在`虚拟地址空间`的`虚拟地址`。
    * 还有一个在`物理地址空间`的 `物理地址`。
    * 两个地址都能访问到这个`字节`。
  * 类似现实世界的**门牌号**, 和**经纬度**。

```text
计算方式如下:      单位换算: K(2^10), M(2^20), G(2^30), T(2^40), P(2^50), E(2^60)
    虚拟地址位数(n)    虚拟地址(N)     最大可能的虚拟地址
        8          2^8 = 256byte      2^8 -1  = 255
        16         2^16=65536=64K     2^16 -1 = 65535
        32         2^32 = 4G          2^32 -1 = 4G-1
        48         2^48 = 256T        2^48 -1 = 256T -1
        64         2^64 = 16E         2^64 -1 = 16E -1
```

## 虚拟内存作为缓存的工具

感悟

> 在讲述这一小章之前，必须交代一下我对`虚拟存储器`概念的**存疑**。  
>   
> 原本我以为`虚拟存储器`=`虚拟内存`。  
>   
> 以下是`虚拟内存`的定义
>
> > **`虚拟内存`是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理`内存碎片`，还有部分暂时存储在外部`磁盘存储器`上，在需要时进行数据交换**
>
> 而在下面的定义我们可以看到`CSAPP`中认为`虚拟存储器`是存放在磁盘上的。  
>   
> 在此，我们姑且当做两者是不同的东西，以后有更深刻的理解，再思考。

`虚拟内存(VM)`被组织为一个存放在**磁盘**上的N个连续字节大小的单元组成的数组。

* 每个字节都有一个唯一的`虚拟地址`，这个虚拟地址作为到数组的索引。
* `磁盘`上数组的内容被缓存到`主存`中。
  * 同存储器层次结构其他缓存一样，`磁盘`上的数据被分割称`块`。
    * 这些`块`作为**磁盘和主存**之间的传输单元。
    * `虚拟页(Virtual Page,VP)`就是这个`块`
      * 每个`虚拟页`大小为`P=2^p`字节。
  * **物理存储器**被分割为`物理页`,大小也为`P`字节
    * 也被称为`页帧(page frame)`
* 任何时候，`虚拟页`的集合都被分为3个不相交的**子集**。

  * **未分配的**:VM系统还未分配\(或者创建\)的页。未分配的`块`没有任何数据与之相关联。
    * 不占用磁盘空间
    * 通过`malloc`来分配
  * **缓存的**：当前缓存在物理存储器的已分配页。
  * **未缓存的**:没有缓存在物理页面存储器中的已分配页。

![](http://i.imgur.com/sD2gAL3.png)

### DRAM缓存的组织结构

`DRAM`表示虚拟存储器系统的缓存，在主存中缓存`虚拟页`,有两个特点。

* `DRAM`缓存不命中处罚十分严重。
  * 因为`磁盘`比`DRAM`慢100000多倍。
* **访问一字节开销**
  * :从一个磁盘的一个扇区读取第一个字节的时间开销要比从该扇区中读连续的字节慢大约100000倍

`DRAM`缓存的组织结构由这种**巨大的不命中开销**驱动。因此有以下特点。  
\(**有些地方不是特别懂，之后看完第六章应该会好点**\)

* `虚拟页`往往很大。
  * 4KB~2MB
  * 访问一字节开销的原因才要这么大。
* `DRAM`缓存是`全相联`
  * 也就是： 任何`虚拟页`都能放在任何`物理页`中。
  * 原因在于**大的不命中惩罚**
* 更精密的**替换算法**
  * 替换错了虚拟页的惩罚很高。
* `DRAM`缓存总是`写回`
  * 因为对磁盘的访问时间很长
  * 而不用`直写`

### 页表



判断**命中**和**替换**又多种软硬件联合提供。

* 操作系统软件，MMU中的地址翻译硬件和`页表(page table)`。
  * `页表`是存放在物理存储器的数据结构。
    * `页表`将虚拟页映射到物理页。
    * **地址翻译硬件**将虚拟地址转换为物理地址都会读取`页表`。
  * 操作系统负责维护`页表`的内容，以及磁盘及DRAM之间来回传送页。

![](http://i.imgur.com/7jov0UO.png)

* `页表`就是一个`页表条目(Page Table Entry,PTE)`的数组.
  * **虚拟地址空间** 中每个页在**页表**的固定偏移量处都有一个`PTE`.
  * 每个`PTE`由一个`有效位`和`n位地址字段`。
    * `有效位`表明虚拟页是否被缓存。
      * 如果有效位存在，那么地址字段指向对应的物理存储器。
      * 如果有效位不存在。
        * 地址字段要么为NULL
        * 要么指向虚拟页在磁盘所在的位置。

### 页命中



![](http://i.imgur.com/3ftwJSs.png)

* 一个**页命中的过程**。
* 一个**虚拟地址**转换为**物理地址**的过程。

### 缺页

在虚拟存储器的习惯说法中，**DRAM缓存不命中**称为`缺页`。

处理过程如下：

* 读取虚拟地址所指向的`PT`。
* 读取`PTE`有效位，发现未被缓存，触发**缺页异常**。
* 调用**缺页异常处理程序**
  * 选择牺牲页。
  * 如果牺牲页发生了改变，将其拷贝回磁盘\(因为是`写回`\)
  * 需要读取的页代替了牺牲页的位置。
  * 结果：牺牲也不被缓存，需要读取的页被缓存。
* 中断结束，重新执行最开始的指令。
* 在`DRAM`中读取成功。

`虚拟存储器`是20世纪60年代发明的，因此即使与SRAM缓存使用了不同的术语。

* `块`被称为`页`。
* **磁盘**和**DRAM**之间传送`页`的活动叫做`交换(swapping)`或者`页面调度(paging)`。
* 有`不命中`发生时，才换入页面，这种策略叫做`按需页面调度(demand paging)`。
  * 现代系统基本都是用这个。

![](.gitbook/assets/ping-mu-kuai-zhao-20190908-xia-wu-9.03.35.png)

### 分配页面

比如某个`页面`所指向地址为`NULL`，将这个地址指向磁盘某处，那么这就叫`分配页面`。

此时`虚拟页`从`未分配`状态 变为 `未缓存`。

![](.gitbook/assets/ping-mu-kuai-zhao-20190908-xia-wu-9.04.52.png)

### 又是局部性拯救了我们



`虚拟存储器`工作的相当好，主要归功于老朋友`局部性(locality)`

尽管从头到尾的**活动页面数量**大于**物理存储器**大小。

但是在局部内，程序往往在一个较小的**活动页面集合**工作

* 这个**集合**叫做`工作集(working set)`或者叫`常驻集(resident set)`
  * 初始载入开销比较大。
* 程序有良好的`时间局部性`，`虚拟存储器`都工作的相当好。
* 如果程序实在很烂，或者物理空间很小，`工作集`大于`物理存储器`大小。这种状态叫`颠簸(thrashing)`.
  * 这时，页面不断换进换出。性能十分低。

> **统计缺页次数**  
>   
> 可以利用Unix的`getrusage`函数检测缺页数量。

## 虚拟存储器作为存储器的管理工具

实际上，操作系统为每个**进程**提供一个独立的`页表`。

![](http://i.imgur.com/2GrCmwH.png)

因此，`VM`简化了`链接`和`加载`,`代码`和`数据共享`,以及应用程序的`存储器`分配。

* **简化链接**
  * 独立的空间地址意味着每个进程的存储器映像使用相同的格式。
    * 文本节总是从`0x08048000`\(32位\)处或`0x400000`\(64位\)处开始。
    * 然后是数据，bss节,栈。
  * 一致性极大简化了`链接器`的设计和实现。
* **简化加载**
  * `加载器`可以从不实际拷贝任何数据从磁盘到存储器。
  * 基本都是**虚拟存储系统**完成。

    > 将一组连续的`虚拟页`映射到任意一个文件中的任意位置的表示法称作`存储器映射`。Unix提供一个称为`mmap`的系统调用，允许程序自己做存储器映射。在9.8详细讲解。
* **简化共享**
  * 独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间的一致`共享`机制.
  * 例子
    * 操作相同的操作系统内核代码
    * C标准库的`printf`.
  * 因此操作系统需要将**不同进程**的适当的虚拟页映射到**相同**的物理页面。
    * 多个进程共享这部分代码的一个拷贝。
    * 而不是每个进程都要加载单独的内核和C标准库的拷贝。
* **简化存储器分配**.
  * 即`虚拟页`连续\(虚拟页还是单独的\)，`物理页`可以不连续。使得分配更加容易。

## 虚拟存储器作为存储器保护的工具

任何现代操作系统必须为操作系统提供手段来**控制**对 **存储器系统**的访问。

* 不应该允许用户进程修改它的只读文本段。
* 不允许它读或修改任何内核的代码和数据结构
* 不允许读写其他进程的私有存储器。
* 不允许修改共享的虚拟页，除非所有共享者显示允许这么做\(通过调用明确的**进程间通信**）

方式：在`PTE`上添加一些格外的`许可位`来控制访问。

![](http://i.imgur.com/lPyVEOn.png)

* `SUP`:是否只有在内核模式下才能访问?
* `READ`：读权限。
* `WRITE`：写权限。

如果指令违反了许可条件，触发**一般保护性异常**，然后交给**异常处理程序**，`Shell`一般会报告为`段错误(segmentaion fault)`。

## 地址翻译



认识到**硬件**在支持虚拟存储器中的角色

以下是接下来可能要用到的符号，作参考。

![](http://i.imgur.com/4BzIrCU.png)

* **形式上**来说，**地址翻译**是一个N元素的虚拟地址空间\(`VAS`\)中的元素和一个M元素的物理地址空间（`PAS`\)元素之间的映射,

  ![](http://i.imgur.com/uxBCPPG.png)

* 以下展示了`MMU`\(`Memory Management Unit`,**存储器管理单元**\)如何利用页表实现这样的功能![](http://i.imgur.com/5ywWZnm.png)
  * `页表基址寄存器(Page Table Base Register,PTBR)`指向当前页表。
  * `n`位的`虚拟地址`包含两个部分
    * 一个`p`位的**虚拟页面偏移**\(`Virtual Page Offset`,`VPO`\)
    * 一个`n-p`位的**虚拟页号**\(`Virtual Page Number`,`VPN`\)
      * `MMU`利用`VPN`选取适当的`PTE(页面条目,Page Tabe Entry,PTE)`
  * `虚拟地址空间  除以  页大小可以得到虚拟页的个数  VPN`
  * **页面条目** \(`PTE`\)中**物理页号\(`PPN`\)**和虚拟地址中的`VPO`串联起啦，即是`物理地址`
    * `PPO`和`VPO`是相同的
    * 不要忘记`VPN`,`PPN`都是块，都是首地址而已，所以需要偏移地址`PPO`,`VPO`
    * `PPN 的位数和 与VPN 的位数可能不相等, 不要被图迷惑.`

![](http://i.imgur.com/LdzzsgW.png)

图\(a\)展示**页面命中**,CPU硬件执行过程

* 第一步：处理器生成虚拟地址，把它传送给`MMU`。
* 第二步: `MMU`生成`PTE`地址\(`PTEA`\)，并从**高速缓存/主存**请求中得到它。
* 第三步: **高速缓存/主存**向MMU返回`PTE`。
* 第四步: `MMU`构造物理地址\(PA\)，并把它传送给**高速缓存/主存**。
* 第五步: **高速缓存/主存**返回所请求的数据字给处理器。

**页面命中**完全由硬件处理，与之不同的是，处理**缺页**需要 硬件和操作系统内核协作完成。

* 第一到三步: 与**命中**时的一样
* 第四步:`PTE`有效位是零，所以`MMU`触发异常，传递CPU中的**控制**到操作系统内核中的 **缺页异常处理程序**。
* 第五步:**缺页异常处理程序**确定出物理存储页中的牺牲页，如果这个页面已经被修改，则把它换出到磁盘。
* 第六步:**缺页异常处理程序**调入新的页面，并更新存储器中的`PTE`。
* 第七部:**缺页异常处理程序**返回到原来的进程，再次执行导致缺页的指令，之后就是**页面命中**一样的步骤。

```text
计算方式:
给定一个32位的虚拟地址空间和一个24位的物理地址,对于下面页大小P,确定 VPN, VPO, PPN 和 PPO的位数
   虚拟地址空间 n = 32 ,物理地址空间 m = 24,P是页面大小 和 n 以及 PTE 有关系: 2^n / 2^m =PTE
      PTE是页面条目, p = log_2(P)
  P=2^p(页面大小)      VPN位数=n-p   VPO位数=p=PPO   PPN位数=m-p   PPO位数=p=VPO
     P                  VPN位数       VPO位数         PPN位数       PPO位数
 1KB (log_2(P)=10)     32-10=22      log_2(P)=10     24-10=14    log_2(P)=10=VPO
    2KB                  21            11               13         11
    4KB                  20            12               12         12
    8KB                  19            13               11         13
```



### 利用 TLB 加速地址翻译 \(VA-&gt;PA\)

每次CPU产生一个虚拟地址，`MMU`就必须查阅一个`PTE`，以便将**虚拟地址**翻译为 **物理地址**。

* 在最糟糕的情况下，会从**内存**中取数据，代价是**几十** 到**几百个**周期
* 如果`PTE`碰巧缓存在`L1`中，那么开销就下降到**一到两个**周期

许多系统都**试图消除这样的开销**，他们在`MMU`中包含了一个关于`PTE`的小缓存，称为`翻译后备缓冲器(Translation Lookaside Buffer,TLB)`。

* `TLB`是一个小的，虚拟寻址的**缓存**。
  * 每一行都保存着一个由单个`PTE`组成的块。
  * `TLB`通常用于高度的**相连性**
  * 如图所示

    ![](http://i.imgur.com/e535Zyz.png)

    ```text
    - 用于组选择和行匹配的`索引`和`标记字段`是从虚拟地址中的**虚拟页号**中提取出来的。
    - 如果`TLB`有T=2^t个组
      - 那么`TLB索引`(`TLBI`)是由VPN的`t`个最低位组成。(对应于`VPO`)
      - `TLB标记`(`TLBT`)是由VPN中剩余位组成(对应于`VPN`)
    ```
* 下图展示了`TLB`命中步骤

  * 关键点:所有的**地址翻译步骤**都是在芯片上的MMU中执行的，因此非常快

  ![](http://i.imgur.com/KKxjJjG.png)

  * `TLB`命中
    * 第一步:CPU产生虚拟地址。
    * 第二步和第三部:`MMU`从`TLB`取出对应的`PTE`。
    * 第四步:`MMU`将这个虚拟地址翻译成一个物理地址，发送到`高速缓存/主存`
    * 第五步:`高速缓存/主存`所请求的数据字返回给CPU
  * 当`TLB`不命中的时候，`MMU`必须从`L1`缓存或内存中取出相应的`PTE`,并进行类似**缺页处理过程**。

### 多级页表

如果我们有一个32位地址空间，`4KB`大小的页面\(`p=2^12`\)和一个`4B`的`PTE`，即使应用所引用的只是虚拟地址空间中很小的一部分，也总是需要一个`4MB`的页表驻留在存储器中。

所以`多级页表`的诞生用于解决**在很少使用时有一个很大的页表常驻于内存**。

> 计算方式，最多可能要`2^32/4KB=1MB` 个页面，每个页面需要4B的`PTE` 所以需要`4MB`大小的页表。
>
> \(2^32/4/1024/1024/1024 = 1MB\)  
>   
> 思考虚拟地址是`31~p`,`p-1~0`即VPN,VPO。  
>   
> `VPN`即可表示页面个数\(上文中的`1MB`\)，`VPO`即页面大小\(上文中的`4KB`\)，显然知道两者相乘为2^32 次方、

用来**压缩**页表的常用方式是使用**层次结构的**页表。

> 页表本身一个优点就是用来解决 内存不够装载程序所用内存的情况，进行动态分配。那么当我们发现内存装载那么大的页表也是负担的时候，显然也可以用类似页表的形式来解决，这就是多级页表。

![](http://i.imgur.com/LPDdUZE.png)

以下用上图的 **两层** 作为例子。

* 总共有`9KB`个页面，PTE为4个字节。
  * 前`2KB`个页面分配给代码和数据。
  * 接下来`6KB`个页面未分配
  * 再接下来`1023`个页面也未分配
  * 接下一个页面分配给用户栈
* 一级页表中的每个`PTE`负责映射虚拟地址空间中一个`4MB`大小的`片(chunk)`.
  * 每一个`片`都是由1024个连续的页面组成。
  * `4MB=1024个页面*PTE大小4字节`。
* 如果`片i`中每个页面都没有分配，那么一级`PTE i`就为空。
  * 例如图中的`PTE 2`~`PTE 7`
  * 但是如果`片i`中有一个被分配了，那么`PTE i`就不能为空。
    * 是不是觉得这样很浪费啊~所以说，`三级四级页表`的原由也是如此。
    * 而且后文会发现，页表级数即使很大，复杂度也不会怎么变化。
* 这种方法从两个方面减少了存储器要求。

  * 如果**一级页表**`PTE`为空，那么相应的**二级页表**就根本不会存在。
    * 一种巨大的潜在节约，大部分时候内存都是未分配的。
  * 只有**一级页表**才需要总是在主存中。
    * 虚拟存储器系统可以在需要时创建，页面调入，调出二级页面，减少主存压力。

  ![](http://i.imgur.com/7ZAlG3U.png)

k级页表层次结构的地址翻译。

* `虚拟地址`被分为`k`个`VPN`和一个`VPO`。每个`VPN i`都是`i-1`级页表到`i`级页表的索引。
* `PPN`存于k级页表。
* `PPO`依旧与`VPO`相同。

此时TLB能发挥作用，因为层次更细，更利于缓存。使得多级页表的地址翻译不比单级页表慢很多。











